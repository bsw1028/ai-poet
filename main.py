from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import streamlit as st
import time
from dotenv import load_dotenv
load_dotenv()

llm =init_chat_model("gpt-4o-mini",model_provider="openai")

prompt = ChatPromptTemplate.from_messages(
    [
        ("system","You are a helpful assistant."),
        ("user","{input}")
    ]
)

output_parser = StrOutputParser()
chain = prompt | llm | output_parser

st.title("ì¸ê³µì§€ëŠ¥ ì‹œì¸")
content = st.text_input("ì‹œì˜ ì£¼ì œë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.")
st.write("ì‹œì˜ ì£¼ì œëŠ”",content)
if st.button("âœğŸ»ì‹œ ì‘ì„± ìš”ì²­í•˜ê¸°", type="secondary") :
    with st.spinner("Wait for it...", show_time=True):
        result = chain.invoke({"input":content+"ì— ëŒ€í•œ ì‹œë¥¼ ì¨ì¤˜"})
    st.success("Done!")
    st.write(result)
